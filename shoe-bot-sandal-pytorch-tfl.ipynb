{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ocanaydin/shoe-bot-sandal-pytorch-tfl?scriptVersionId=113973037\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\n\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\ncudnn.benchmark = True\nplt.ion()   # interactive mode","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:33:17.812387Z","iopub.execute_input":"2022-10-17T20:33:17.813592Z","iopub.status.idle":"2022-10-17T20:33:20.052624Z","shell.execute_reply.started":"2022-10-17T20:33:17.813547Z","shell.execute_reply":"2022-10-17T20:33:20.051636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATA TRANSFORMS**","metadata":{}},{"cell_type":"code","source":"\"\"\"Data Augmentation and Normalization for train images.Test and Val images are proccessed only with normalization\"\"\"\ndata_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.76891514,0.77947596,0.80775537],[0.33321657,0.32545126,0.30419493])\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:33:20.054639Z","iopub.execute_input":"2022-10-17T20:33:20.055207Z","iopub.status.idle":"2022-10-17T20:33:20.060666Z","shell.execute_reply.started":"2022-10-17T20:33:20.055169Z","shell.execute_reply":"2022-10-17T20:33:20.059708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LOAD IMAGES**","metadata":{}},{"cell_type":"code","source":"data_dir = \"../input/shoe-vs-sandal-vs-boot-dataset-15k-images/Shoe vs Sandal vs Boot Dataset\"\ndataset = datasets.ImageFolder(data_dir,transform = data_transforms)\n\"\"\"Split dataset as train,test and val.\"\"\"\ntrain_size = int(len(dataset) * 0.7)\nval_size = (len(dataset) - train_size) // 2\ntest_size = val_size\nprint(f\"Train Size : {train_size} Val Size : {val_size} Test Size : {test_size}\")","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:33:26.632455Z","iopub.execute_input":"2022-10-17T20:33:26.632852Z","iopub.status.idle":"2022-10-17T20:33:28.989335Z","shell.execute_reply.started":"2022-10-17T20:33:26.63282Z","shell.execute_reply":"2022-10-17T20:33:28.987997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DIVIDE DATASET**","metadata":{}},{"cell_type":"code","source":"\"\"\"Use random split to divide dataset.\"\"\"\ntrain_data,val_data,test_data = torch.utils.data.random_split(dataset,[train_size,val_size,test_size],\n                                                              generator = torch.Generator().manual_seed(42))\n\nclass_names = train_data.dataset.classes\n","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:33:29.671245Z","iopub.execute_input":"2022-10-17T20:33:29.671605Z","iopub.status.idle":"2022-10-17T20:33:29.679277Z","shell.execute_reply.started":"2022-10-17T20:33:29.671574Z","shell.execute_reply":"2022-10-17T20:33:29.678279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATA LOADERS**","metadata":{}},{"cell_type":"code","source":"batch_size = 64\ntrain_loader = torch.utils.data.DataLoader(train_data,batch_size = batch_size,shuffle = True)\nval_loader = torch.utils.data.DataLoader(val_data,batch_size = batch_size,shuffle = True)\ntest_loader = torch.utils.data.DataLoader(test_data,batch_size = batch_size,shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:33:30.458678Z","iopub.execute_input":"2022-10-17T20:33:30.459385Z","iopub.status.idle":"2022-10-17T20:33:30.465927Z","shell.execute_reply.started":"2022-10-17T20:33:30.459349Z","shell.execute_reply":"2022-10-17T20:33:30.46446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**VISUALIZATION OF IMAGES**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef imshow(inp,title = None):\n    inp = inp.numpy().transpose((1,2,0))\n    mean = np.array([0.76891514,0.77947596,0.80775537])\n    std = np.array([0.33321657,0.32545126,0.30419493])\n    inp = std * inp + mean\n    inp = np.clip(inp,0,1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n\n\"\"\"Get a batch of training_data\"\"\"\ninputs,classes = next(iter(test_loader))\n\"\"\"Make a grid from batch.\"\"\"\nout = torchvision.utils.make_grid(inputs[0 : 6])\nimshow(out,title = [class_names[x] for x in classes[0:6]])","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:33:31.62014Z","iopub.execute_input":"2022-10-17T20:33:31.621267Z","iopub.status.idle":"2022-10-17T20:33:32.309692Z","shell.execute_reply.started":"2022-10-17T20:33:31.62122Z","shell.execute_reply":"2022-10-17T20:33:32.308624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TRAINING**","metadata":{}},{"cell_type":"code","source":"dataloaders = {\"train\" : train_loader,\"val\" : val_loader,\"test\" : test_loader}\ndevice = torch.device(\"cuda:0\"if torch.cuda.is_available() else \"cpu\")\ndataset_sizes = {\"train\" : train_size,\"val\" : val_size,\"test\" : test_size}\ndef train_model(model,criterion,optimizer,scheduler,num_epochs = 25):\n   #Define time and best model weights to save.\n   since = time.time()\n   best_model_wts = copy.deepcopy(model.state_dict())\n   best_acc = 0.0\n   for epoch in range(num_epochs):\n     print(f\"Epoch : {epoch+1} / {num_epochs }\")\n     print(\"-\" * 10)\n     #Each epoch has training and validation phase.\n     for phase in [\"train\",\"val\"]:\n       if phase == \"train\":\n         model.train()\n       else:\n         model.eval()\n       running_loss = 0.0\n       running_corrects = 0\n       #Iterate over data.\n       for inputs,labels in dataloaders[phase]:\n         #Move tensors to gpu.\n         inputs = inputs.to(device)\n         labels = labels.to(device)\n         #Zero Gradients.\n         optimizer.zero_grad()\n         #Forward\n         #Track history if only in train.\n         with torch.set_grad_enabled(phase == \"train\"):\n           #Get preds in train and calculate loss.\n           outputs = model(inputs)\n           _,preds = torch.max(outputs,1)\n           loss = criterion(outputs,labels)\n           #Backward in train phase.\n           if phase == \"train\":\n             loss.backward()\n             optimizer.step()\n         #statistics\n         running_loss += loss.item() * inputs.size(0)\n         running_corrects += torch.sum(preds == labels.data)\n    \n       if phase == \"train\":\n         scheduler.step()\n\n       epoch_loss = running_loss / dataset_sizes[phase]\n       epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n       print(f\"{phase} Loss : {epoch_loss} Acc {epoch_acc}\")\n       #Deep copy of the model.\n       if phase == \"val\" and epoch_acc > best_acc:\n         best_acc = epoch_acc\n         best_model_wts = copy.deepcopy(model.state_dict())\n\n     print()\n  \n   time_elapsed = time.time() - since\n   print(f\"Training completed in : {time_elapsed // 60}m in {time_elapsed % 60}\")\n   print(f\"Best val acc : {best_acc}\")\n\n   #Load model best weights.\n   model.load_state_dict(best_model_wts)\n   return model\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:33:33.317421Z","iopub.execute_input":"2022-10-17T20:33:33.318988Z","iopub.status.idle":"2022-10-17T20:33:33.388964Z","shell.execute_reply.started":"2022-10-17T20:33:33.318944Z","shell.execute_reply":"2022-10-17T20:33:33.387849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FINETUNING THE CONVNET**","metadata":{}},{"cell_type":"code","source":"model_ft = models.resnet18(pretrained=True)\nnum_features = model_ft.fc.in_features\n#Output layer\nmodel_ft.fc = nn.Linear(in_features=num_features,out_features = len(class_names))\n#Move to gpu and define loss.\nmodel_ft = model_ft.to(device)\ncriterion = nn.CrossEntropyLoss()\n#Optimizer\noptimizer_ft = optim.SGD(model_ft.parameters(),lr = 0.001,momentum = 0.9)\n#Decay LR by a factor 0.1\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft,step_size = 5,gamma = 0.1)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:33:34.305536Z","iopub.execute_input":"2022-10-17T20:33:34.306238Z","iopub.status.idle":"2022-10-17T20:33:37.992893Z","shell.execute_reply.started":"2022-10-17T20:33:34.306203Z","shell.execute_reply":"2022-10-17T20:33:37.991889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = train_model(model_ft,criterion,optimizer_ft,exp_lr_scheduler,3)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:33:39.894501Z","iopub.execute_input":"2022-10-17T20:33:39.897548Z","iopub.status.idle":"2022-10-17T20:37:22.363149Z","shell.execute_reply.started":"2022-10-17T20:33:39.897495Z","shell.execute_reply":"2022-10-17T20:37:22.361948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model,num_images = 6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    \n    with torch.no_grad():\n        for i,(inputs,labels) in enumerate(dataloaders[\"val\"]):\n            #Move tensors to gpu\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            #Forward\n            outputs = model(inputs)\n            _,preds = torch.max(outputs,1)\n            for j in range(inputs.size()[0]):\n                #Show validation images and predictions.\n                images_so_far += 1\n                ax = plt.subplot(num_images // 2,2,images_so_far)\n                ax.axis(\"off\")\n                ax.set_title(f\"Predicted : {class_names[preds[j]]}\")\n                imshow(inputs.cpu().data[j])\n                \n                if images_so_far == num_images:\n                    model.train(mode = was_training)\n                    return\n    model.training(mode = was_training)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:37:29.589175Z","iopub.execute_input":"2022-10-17T20:37:29.589545Z","iopub.status.idle":"2022-10-17T20:37:29.597926Z","shell.execute_reply.started":"2022-10-17T20:37:29.589507Z","shell.execute_reply":"2022-10-17T20:37:29.596635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model(model_ft,6)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:37:35.199449Z","iopub.execute_input":"2022-10-17T20:37:35.199859Z","iopub.status.idle":"2022-10-17T20:37:35.987526Z","shell.execute_reply.started":"2022-10-17T20:37:35.199826Z","shell.execute_reply":"2022-10-17T20:37:35.986555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SAVE MODEL**","metadata":{}},{"cell_type":"code","source":"import os\ntorch.save(model.state_dict(),\"shoe_bot_sandal_TFL.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LOAD MODEL**","metadata":{}},{"cell_type":"code","source":"model1 = model_ft\nmodel1.load_state_dict(torch.load(\"shoe_bot_sandal_TFL.h5\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**GET IMAGE FROM INTERNET AND PREDICT IT**","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport requests\nfrom io import BytesIO\ndef get_process_img(url):\n    #Load image from url.\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    #Apply transform to image as train,test images.\n    img = data_transforms(img)\n    return img\n    ","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:37:46.732771Z","iopub.execute_input":"2022-10-17T20:37:46.733448Z","iopub.status.idle":"2022-10-17T20:37:46.739415Z","shell.execute_reply.started":"2022-10-17T20:37:46.733411Z","shell.execute_reply":"2022-10-17T20:37:46.738112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\"if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\ndef pred_single_img(img):\n    #Move img to device.\n    img = img.to(device)\n    #Prediction.\n    outputs = model(img.unsqueeze(0))\n    _,preds = torch.max(outputs,1)\n    #Return prediction with using indexes.\n    result = class_names[preds.item()]\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:37:59.304837Z","iopub.execute_input":"2022-10-17T20:37:59.305199Z","iopub.status.idle":"2022-10-17T20:37:59.313734Z","shell.execute_reply.started":"2022-10-17T20:37:59.30517Z","shell.execute_reply":"2022-10-17T20:37:59.3127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Paste url and get img.\"\"\"\nurl = \"https://productimages.hepsiburada.net/s/58/600-800/11315175456818.jpg\"\nimg = get_process_img(url)\n\"\"\"Print pred.\"\"\"\npred = pred_single_img(img)\nprint(f\"Prediction is : {pred}\")\n\"\"\"Show img.\"\"\"\nplt.imshow(img.permute(1,2,0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T20:38:04.310191Z","iopub.execute_input":"2022-10-17T20:38:04.310549Z","iopub.status.idle":"2022-10-17T20:38:04.802358Z","shell.execute_reply.started":"2022-10-17T20:38:04.31052Z","shell.execute_reply":"2022-10-17T20:38:04.80132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}